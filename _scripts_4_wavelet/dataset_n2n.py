# E:\LD-CT SR\_scripts_4_wavelet\dataset_n2n.py
# 2.5D Neighboring-Slice Self-Supervised Dataset for SwinIR
#
# ì…ë ¥ : [3, H, W]  (z-1, z, z+1 ìŠ¬ë¼ì´ìŠ¤ ìŠ¤íƒ)
# íƒ€ê¹ƒ : [1, H, W]  (ì¤‘ì•™ ìŠ¬ë¼ì´ìŠ¤ z)
#
# - HU ìœˆë„ìš°ë§ í›„ [0,1] ì •ê·œí™”
# - ëœë¤ íŒ¨ì¹˜ í¬ë¡­ (patch_size)
# - train/val/test ëª¨ë‘ ê°™ì€ Dataset í´ë˜ìŠ¤ ì‚¬ìš© (random_split)

import random
from pathlib import Path

import nibabel as nib
import numpy as np
import torch
from torch.utils.data import Dataset


class NCCTDenoiseDataset(Dataset):
    def __init__(
        self,
        nc_ct_dir,
        hu_window=(-160, 240),
        patch_size=128,
        mode="train",
        min_body_fraction=0.05,
    ):
        """
        nc_ct_dir: NIfTI(.nii/.nii.gz) NC-CT ë³¼ë¥¨ í´ë”
        hu_window: (minHU, maxHU)
        patch_size: ì •ì‚¬ê°í˜• íŒ¨ì¹˜ í¬ê¸°
        mode: 'train' / 'val' / 'test' (í˜„ì¬ëŠ” ë™ì‘ ë™ì¼, ì¶”í›„ í•„ìš” ì‹œ ë¶„ê¸° ê°€ëŠ¥)
        min_body_fraction: slice ì•ˆì—ì„œ body(ì¡°ì§) ë¹„ìœ¨ì´ ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ì œì™¸
        """
        super().__init__()
        self.nc_ct_dir = Path(nc_ct_dir)
        self.hu_min, self.hu_max = hu_window
        self.patch_size = patch_size
        self.mode = mode
        self.min_body_fraction = min_body_fraction

        self.files = sorted(
            list(self.nc_ct_dir.glob("*.nii.gz")) +
            list(self.nc_ct_dir.glob("*.nii"))
        )
        if len(self.files) == 0:
            raise FileNotFoundError(f"No NIfTI files found in {self.nc_ct_dir}")

        # ë©”ëª¨ë¦¬ì— ì „ë¶€ ì ì¬ (ë°ì´í„° ìˆ˜ê°€ í¬ì§€ ì•Šë‹¤ëŠ” ì „ì œ; ì§€ê¸ˆ í”„ë¡œì íŠ¸ ê·œëª¨ë©´ OK)
        self.volumes = []
        self.slice_index = []  # (vol_idx, z)

        print(f"\nğŸ“‚ Loading NC-CT volumes for NS-N2N dataset...")
        for vol_idx, path in enumerate(self.files):
            nii = nib.load(str(path))
            vol = nii.get_fdata().astype(np.float32)
            # NaN/inf ë°©ì§€
            vol = np.nan_to_num(vol, nan=0.0, posinf=0.0, neginf=0.0)

            H, W, D = vol.shape
            self.volumes.append(vol)

            # z=1 ~ D-2 ë§Œ ì‚¬ìš© (ì–‘ ëì€ ì´ì›ƒ ìŠ¬ë¼ì´ìŠ¤ ë¶€ì¡±)
            for z in range(1, D - 1):
                slice_2d = vol[:, :, z]

                # body mask: ì•½í•œ ì¡°ê±´ìœ¼ë¡œ ëŒ€ëµì ì¸ ì‹ ì²´ ì˜ì—­ë§Œ ë‚¨ê¹€
                body_mask = (slice_2d > -500) & (slice_2d < 500)
                body_frac = body_mask.sum() / float(H * W)
                if body_frac < self.min_body_fraction:
                    continue

                self.slice_index.append((vol_idx, z))

        if len(self.slice_index) == 0:
            raise RuntimeError("No valid slices found for NS-N2N dataset.")

        print(f"   Loaded {len(self.files)} volumes, "
              f"{len(self.slice_index)} usable slices (mode={self.mode})")

    def __len__(self):
        return len(self.slice_index)

    def _window_and_normalize(self, slice_2d: np.ndarray) -> np.ndarray:
        s = np.clip(slice_2d, self.hu_min, self.hu_max)
        s = (s - self.hu_min) / (self.hu_max - self.hu_min + 1e-8)
        return s.astype(np.float32)

    def _random_crop(self, arr: np.ndarray) -> np.ndarray:
        """arr: [..., H, W]"""
        if self.patch_size is None:
            return arr
        H, W = arr.shape[-2:]
        if H <= self.patch_size or W <= self.patch_size:
            return arr

        top = random.randint(0, H - self.patch_size)
        left = random.randint(0, W - self.patch_size)
        return arr[..., top:top + self.patch_size, left:left + self.patch_size]

    def __getitem__(self, idx):
        vol_idx, z = self.slice_index[idx]
        vol = self.volumes[vol_idx]

        s0 = self._window_and_normalize(vol[:, :, z - 1])
        s1 = self._window_and_normalize(vol[:, :, z])
        s2 = self._window_and_normalize(vol[:, :, z + 1])

        # [3, H, W], [H, W]
        stack = np.stack([s0, s1, s2], axis=0)
        target = s1  # ì¤‘ì•™ ìŠ¬ë¼ì´ìŠ¤

        # ëœë¤ íŒ¨ì¹˜ í¬ë¡­ (train/val/test ëª¨ë‘ ë™ì¼í•˜ê²Œ; random_splitìœ¼ë¡œ ë‚˜ë‰˜ë¯€ë¡œ OK)
        stack = self._random_crop(stack)
        target = self._random_crop(target)

        input_tensor = torch.from_numpy(stack)              # [3, H, W]
        target_tensor = torch.from_numpy(target).unsqueeze(0)  # [1, H, W]

        return input_tensor, target_tensor
